{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2340,"status":"ok","timestamp":1682349491448,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"6qGq8OeftJhc"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow_datasets as tfds\n","import numpy as np\n","import os"]},{"cell_type":"markdown","source":["This is the code fot the simple model that uses Mnist"],"metadata":{"id":"i0q-UzDCvoMH"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"3__s4949tOVd","executionInfo":{"status":"ok","timestamp":1682349491800,"user_tz":-120,"elapsed":356,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"}}},"outputs":[],"source":["(ds_train, ds_test), ds_info = tfds.load(\n","    'mnist',\n","    split = ['train', 'test'],\n","    shuffle_files=True,\n","    as_supervised=True,\n","    with_info=True,\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682349491801,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"ATJm1hd1y4SW"},"outputs":[],"source":["#ds_train = train_ds_gen\n","#ds_test = train_ds_gen"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682349491801,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"XqtVHaqOoNxU"},"outputs":[],"source":["def normalize_img(image, label):\n","  return tf.cast(image, tf.float32) / 255., label"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"NLlIVaX2ohYa","executionInfo":{"status":"ok","timestamp":1682349491801,"user_tz":-120,"elapsed":4,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"}}},"outputs":[],"source":["ds_train = ds_train.map(\n","    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n","ds_train = ds_train.cache()\n","ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n","ds_train = ds_train.batch(128)\n","ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"e3Uz8d4OyB4A","executionInfo":{"status":"ok","timestamp":1682349491801,"user_tz":-120,"elapsed":4,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"}}},"outputs":[],"source":["ds_test = ds_test.map(\n","    normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n","ds_test = ds_test.batch(128)\n","ds_test = ds_test.cache()\n","ds_test = ds_test.prefetch(tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32532,"status":"ok","timestamp":1682349524330,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"Gn6lK6RayiTP","outputId":"e657afd9-1fd3-46e9-d8eb-bb8066f287e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/6\n","469/469 [==============================] - 14s 12ms/step - loss: 0.3550 - sparse_categorical_accuracy: 0.9013 - val_loss: 0.1956 - val_sparse_categorical_accuracy: 0.9425\n","Epoch 2/6\n","469/469 [==============================] - 2s 4ms/step - loss: 0.1650 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.1424 - val_sparse_categorical_accuracy: 0.9596\n","Epoch 3/6\n","469/469 [==============================] - 2s 4ms/step - loss: 0.1218 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.1134 - val_sparse_categorical_accuracy: 0.9666\n","Epoch 4/6\n","469/469 [==============================] - 2s 3ms/step - loss: 0.0957 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.1009 - val_sparse_categorical_accuracy: 0.9701\n","Epoch 5/6\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0776 - sparse_categorical_accuracy: 0.9768 - val_loss: 0.0881 - val_sparse_categorical_accuracy: 0.9730\n","Epoch 6/6\n","469/469 [==============================] - 2s 5ms/step - loss: 0.0644 - sparse_categorical_accuracy: 0.9810 - val_loss: 0.0821 - val_sparse_categorical_accuracy: 0.9747\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7efbb17fe3d0>"]},"metadata":{},"execution_count":7}],"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(10)\n","])\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",")\n","\n","model.fit(\n","    ds_train,\n","    epochs=6,\n","    validation_data = ds_test\n",")"]},{"cell_type":"markdown","source":["From here there is my attempt at creating my datagenerator. First I save the files in a directory called 'data'."],"metadata":{"id":"qsc1Ow1dv5bC"}},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682349524330,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"-PLUTqNXTpmf"},"outputs":[],"source":["#os.mkdir('data')"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682349524331,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"tX0S-Q-k88rm"},"outputs":[],"source":["(mnist_train, mnist_test)= tfds.load(\n","    'mnist',\n","    split = ['train', 'test'],\n","    shuffle_files=True,\n","    as_supervised=True\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682349524331,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"fHMNseWY9Zd8"},"outputs":[],"source":["iter_train = mnist_train.as_numpy_iterator()\n","iter_test = mnist_test.as_numpy_iterator()"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682349524331,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"vgPP3v0N9anU"},"outputs":[],"source":["lista_train = []\n","lista_test = []"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45368,"status":"ok","timestamp":1682349569687,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"FcS3UGYiNp4h","outputId":"363c2138-5fa4-42e9-eb21-77a4c716bc8c"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]}],"source":["#I use np.save, but there probably are some problems with the format of files\n","#as I get a Warning of Visible Deprecation. I tried solving it by allowing pickle\n","\n","offset = 0\n","for i, el in enumerate(iter_train):\n","  np.save('data/arr'+str(i), el, allow_pickle=True)\n","  lista_train.append('arr'+str(i))\n","  offset = i + 1\n","for i, el in enumerate(iter_test):\n","  np.save('data/arr'+str(i + offset), el, allow_pickle=True)\n","  lista_test.append('arr'+str(i + offset))\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1682349569687,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"u-nCumGkaCr1","outputId":"7dbaf96e-ccdf-473e-d9eb-c8a8cf6a354c"},"outputs":[{"output_type":"stream","name":"stdout","text":["arr59999\n","arr60000\n"]}],"source":["#just checking that the lists are correct\n","print(lista_train[-1])\n","print(lista_test[0])"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682349569688,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"417WvihEuEnr"},"outputs":[],"source":["labels_train = {e[1] : e[0] for e in enumerate(lista_train)}\n","labels_test = {e[1] : e[0] for e in enumerate(lista_test)}"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682349569688,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"s2oGpGkpbCIU"},"outputs":[],"source":["partition = {'train' : lista_train, 'test' : lista_test}"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682349569688,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"9QIcrhpkbKrU"},"outputs":[],"source":["#This is the code for the custom datagenerator, that should go in a separate script\n","\n","class DataGenerator(keras.utils.Sequence):\n","    'Generates data for Keras'\n","    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n","                 n_classes=10, shuffle=True):\n","        'Initialization'\n","        self.dim = dim\n","        self.batch_size = batch_size\n","        self.labels = labels\n","        self.list_IDs = list_IDs\n","        self.n_channels = n_channels\n","        self.n_classes = n_classes\n","        self.shuffle = shuffle\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(np.floor(len(self.list_IDs) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        # Find list of IDs\n","        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(list_IDs_temp)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_IDs))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, list_IDs_temp):\n","        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n","        y = np.empty((self.batch_size), dtype=int)\n","\n","        # Generate data\n","        for i, ID in enumerate(list_IDs_temp):\n","            # Store sample\n","            X[i,] = np.load('data/' + ID + '.npy', allow_pickle = True)\n","\n","            # Store class\n","            y[i] = self.labels[ID]\n","\n","        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1682349569688,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"BvG_DoWqo-BF"},"outputs":[],"source":["params = {'dim': (28, 28),\n","          'batch_size': 64,\n","          'n_classes': 6,\n","          'n_channels': 1,\n","          'shuffle': True}"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682349569689,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"GwYEvdGVxxJ4"},"outputs":[],"source":["train_ds_gen = DataGenerator(partition['train'], labels_train, **params)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1682349569689,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"E9rP7vbRyVuB"},"outputs":[],"source":["test_ds_gen = DataGenerator(partition['test'], labels_test, **params)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"executionInfo":{"elapsed":916,"status":"error","timestamp":1682349570601,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"},"user_tz":-120},"id":"72sNdGXFyv5j","outputId":"979b10a1-f1ba-4970-e230-eca4c4b36e85"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-20-83ef88b6e7d6>:12: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-83ef88b6e7d6>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m model.fit_generator(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m         )\n\u001b[0;32m-> 2636\u001b[0;31m         return self.fit(\n\u001b[0m\u001b[1;32m   2637\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-2f3d929b1860>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Generate data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-2f3d929b1860>\u001b[0m in \u001b[0;36m__data_generation\u001b[0;34m(self, list_IDs_temp)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Store sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mID\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Store class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2,) into shape (28,28,1)"]}],"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  tf.keras.layers.Dense(128, activation='relu'),\n","  tf.keras.layers.Dense(10)\n","])\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(0.001),\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",")\n","\n","model.fit_generator(\n","    generator = train_ds_gen,\n","    epochs=6,\n","    validation_data = test_ds_gen\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7k6ziXze70-W","executionInfo":{"status":"aborted","timestamp":1682349570602,"user_tz":-120,"elapsed":7,"user":{"displayName":"Aster Stear","userId":"08717517503324891683"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMYpQmnZyjfcWg2BFaY047l"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}