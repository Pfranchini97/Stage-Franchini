{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d5f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import Phylo\n",
    "from Bio import AlignIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "#import pylab\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "#import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import pygraphviz as pgv\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx import all_pairs_shortest_path_length\n",
    "import hyperlib\n",
    "from hyperlib.embedding.treerep import treerep\n",
    "from hyperlib.embedding.sarkar import sarkar_embedding\n",
    "from hyperlib.utils.multiprecision import poincare_dist\n",
    "from hyperlib.utils.multiprecision import poincare_reflect0\n",
    "#from hyperlib.manifold.lorentz import Lorentz\n",
    "#from hyperlib.manifold.poincare import Poincare\n",
    "import mpmath as mpm\n",
    "from scipy.special import expit\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c689f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './205_na_aln.fa'\n",
    "file_format = 'fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a767ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = AlignIO.read(file_name, file_format)\n",
    "#print(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2874c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i:seq.id for i, seq in enumerate(aln)}\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln_length = aln.get_alignment_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77edd20",
   "metadata": {},
   "source": [
    "sotto il modulo treeconstruction di Phylo c'è questo DistanceCalculator che calcola automaticamente le distanze secondo un modello dato come input, 'identity' di default.\n",
    "il metodo get_distance produce un oggetto di tipo DistanceMatrix, che va quindi converito con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dcfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Phylo.TreeConstruction.DistanceMatrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = DistanceCalculator('trans')\n",
    "dm = calc.get_distance(aln)\n",
    "#print(dm)\n",
    "type(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602de307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.array(dm)\n",
    "#dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8687d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = DistanceTreeConstructor()\n",
    "ptree = constructor.upgma(dm)\n",
    "ptree.ladderize()\n",
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8c3d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x13076da15b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree = treerep(dist_mat,return_networkx = True, tol = 0.0000000000000000000000001)\n",
    "htree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7208ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699f739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesi_aggiornati = [(edge[0], edge[1], {'weight' : expit(htree.get_edge_data(edge[0], edge[1])['weight'])}) for edge in list(htree.edges)]\n",
    "#pesi_aggiornati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cd360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pesi_aggiornati:\n",
    "    htree.update([i])\n",
    "htree.get_edge_data(4, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b29ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({33: {'weight': 0.5}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4941e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "htgraph = nx.nx_agraph.to_agraph(htree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8315c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#htgraph.layout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678adb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htgtwopi = htgraph\n",
    "htgtwopi.layout(prog = 'twopi') #dot, neato\n",
    "#htgtwopi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831659dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 224 nodes and 223 edges\n"
     ]
    }
   ],
   "source": [
    "print(htree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd9d2b",
   "metadata": {},
   "source": [
    "Infine il codice suggerito nell'esempio della libreria su github che dovrebbe fare l'embedding iperbolico nella sfera di Poincaré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4798b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('182.3930140184730296830577818620853629355128624706745952553613730108328677888921117463192282011772899928295324397826630587037104171664147009266325151865162568555755224573700242316251616213378906730657917555326376907130667781711161946561635505501557502749903012449283476284226224131427363125102892699180013462569534431948250584')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 0 # label of root node\n",
    "tau = 0.2 # scaling factor for edges\n",
    "embed_2D = sarkar_embedding(htree, root)\n",
    "\n",
    "# calculate hyperbolic distances from the embedding\n",
    "poincare_dist(embed_2D[0,:], embed_2D[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927924e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#embed_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67aaa18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix(\n",
       "[['-0.000003423767373985497984751829356124747085063760477591075834961990692450826259296341224306019947944315079684713212979073356493723219441847436171787303741494917810710510838979120572783480491943591745672352197053777428079487765954959897686032287107621031035249424852628182889140779419344143473784514951479874114276130901639076456', '0.005231774456298183848868269141325044776261945825202421062376019137696801914050044753010894185013976064400681042387321046914197558385284662849526699172849311596174751965364629275793968615729134769901644605393966053989845375783867845587629778476655030500633610682487087931944236830809385226817972148091128030929594756482837622']])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_2D[2, :] - embed_2D[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35341",
   "metadata": {},
   "source": [
    "# **Codice di preparazione per H-depp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "825a0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69f17fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import DataGenerator\n",
    "from src.loss_function import hdepp_loss_couple\n",
    "from src.loss_function import hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "293aed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_riemopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b026d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_nodes = len(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7958a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dist = dict(all_pairs_shortest_path_length(htree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83854bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_tensor = tf.convert_to_tensor([[tree_dist[i][j] for j in range(0, original_nodes)] for i in range(0, original_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d758b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([205, 205])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cddb904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad1523",
   "metadata": {},
   "source": [
    "**Distortions of the old embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "251d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('183.5706887125437275012669761316737293472617396839872234836643717924866364940717333990487804252432743470169131907996470112513843975258455353536347153842456837294554564308593777892772591629778012512753187676099243081539128496201698145316497961309813613126520098908361853240154806379715122640915085424493210542363988208267386476')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dist = {}\n",
    "\n",
    "#note that i use poincare_dist to calculate the embeddings distance\n",
    "#we might want to calculate it differently\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = poincare_dist(embed_2D[i,:], embed_2D[j,:])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    emb_dist[inode] = temp_dict\n",
    "\n",
    "emb_dist[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1d8617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_func(e_dist, t_dist):\n",
    "    if (t_dist != 0):\n",
    "        return np.square(( e_dist / t_dist ) - 1) \n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11b0597d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('4.95021677894868878817336334564908546740134272664065431651070898600347645811634249429357125024968430692939913138850955383342030083736693737043879145601905638699703476019557666213811223948491572384014138730421419884895025299168795358490885744883002682359412122892913711795255528735768967170928689282513655583160863458363731869')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortion = {}\n",
    "\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = distortion_func(emb_dist[i][j], tree_dist[i][j])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    distortion[inode] = temp_dict\n",
    "    \n",
    "distortion[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de77ff8",
   "metadata": {},
   "source": [
    "**Encoding the sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "458e3c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATGAGCCAAGAAGAAAAGTTACCAAAGATTCTGATCGTTGAAGACGACGAGCGT...TTG')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln[0].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "182ba07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_dict = {'A' : np.array([0, 0, 0, 1]),\n",
    "           'T' : np.array([0, 0, 1, 0]),\n",
    "           'G' : np.array([0, 1, 0, 0]),\n",
    "           'C' : np.array([1, 0, 0, 0]),\n",
    "           '-' : np.array([0, 0, 0, 0]),}\n",
    "hot_dict[aln[0].seq[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48ba949e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_seqs = [np.array([hot_dict[car] for car in alignment.seq]) for alignment in aln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67c6fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = [[(encoded_seqs[i], encoded_seqs[j], tree_dist[i][j]) for j in tree_dist[i] if j < original_nodes] for i in tree_dist if i < original_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945eed7",
   "metadata": {},
   "source": [
    "**Train and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03eadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_IDs_train = [[i, j] for j in range(0, 22) for i in range(0, 22)]\n",
    "#lista_IDs_val = [[i, j] for j in range(22, 29) for i in range(22, 29)] #what should I use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8de4ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_train = [i for i in range(0, original_nodes-30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "047b1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_val = [i for i in range(original_nodes-30, original_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5cca52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (aln_length, ),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': aln_length, #shouldn't be categorical\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "#da correggere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "54667860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_gen = DataGenerator(lista_IDs_train, model_inputs, **params)\n",
    "test_ds_gen = DataGenerator(lista_IDs_val, model_inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c49f587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperlib.nn.layers.lin_hyp import LinearHyperbolic\n",
    "from hyperlib.nn.optimizers.rsgd import RSGD\n",
    "from hyperlib.manifold.poincare import Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50c1c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "baee04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow_riemopt.optimizers.RiemannianSGD??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "821593a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.SGD(learning_rate=1e-9, clipnorm = 1.0, clipvalue = 0.5)\n",
    "#optimizer = RSGD(learning_rate = 0.1)\n",
    "optimizer = tensorflow_riemopt.optimizers.RiemannianSGD(learning_rate = 1e-3)\n",
    "loss_fn = hdepp_loss\n",
    "\n",
    "#, clipnorm = 1.0, clipvalue = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "376d8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.layers.LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcdf2bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\\n    #sparse vs non sparse\\n)\\n\\nmodel.fit(\\n    train_ds_gen,\\n    epochs=9,\\n    validation_data = test_ds_gen\\n)\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Flatten(input_shape=(714, 4)),\n",
    "    tf.keras.Input((714, 4), 16),\n",
    "    \n",
    "    tf.keras.layers.Conv1D(8, 1),\n",
    "    tf.keras.layers.Conv1D(3, 5),\n",
    "    tf.keras.layers.Conv1D(2, 5)\n",
    "    #tf.keras.layers.LSTM(15)\n",
    "    #LinearHyperbolic(10, Poincare(), 1)\n",
    "    #tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "\n",
    "#, kernel_regularizer = 'L2'\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    "    #sparse vs non sparse\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds_gen,\n",
    "    epochs=9,\n",
    "    validation_data = test_ds_gen\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37569f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.apply_gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4fde855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function RiemannianSGD._resource_apply_dense at 0x000001303D0E0940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function RiemannianSGD._resource_apply_dense at 0x000001303D0E0940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0 tf.Tensor(146.74382, shape=(), dtype=float32)\n",
      "1 tf.Tensor(183.563, shape=(), dtype=float32)\n",
      "2 tf.Tensor(166.99803, shape=(), dtype=float32)\n",
      "3 tf.Tensor(160.55534, shape=(), dtype=float32)\n",
      "4 tf.Tensor(148.6356, shape=(), dtype=float32)\n",
      "5 tf.Tensor(142.46358, shape=(), dtype=float32)\n",
      "6 tf.Tensor(139.70845, shape=(), dtype=float32)\n",
      "7 tf.Tensor(138.79482, shape=(), dtype=float32)\n",
      "8 tf.Tensor(153.89404, shape=(), dtype=float32)\n",
      "9 tf.Tensor(158.19034, shape=(), dtype=float32)\n",
      "10 tf.Tensor(173.89456, shape=(), dtype=float32)\n",
      "end of epoch number:  1\n",
      "0 tf.Tensor(146.7438, shape=(), dtype=float32)\n",
      "1 tf.Tensor(183.56299, shape=(), dtype=float32)\n",
      "2 tf.Tensor(166.998, shape=(), dtype=float32)\n",
      "3 tf.Tensor(160.55531, shape=(), dtype=float32)\n",
      "4 tf.Tensor(148.63557, shape=(), dtype=float32)\n",
      "5 tf.Tensor(142.46358, shape=(), dtype=float32)\n",
      "6 tf.Tensor(139.70842, shape=(), dtype=float32)\n",
      "7 tf.Tensor(138.79478, shape=(), dtype=float32)\n",
      "8 tf.Tensor(153.89403, shape=(), dtype=float32)\n",
      "9 tf.Tensor(158.19029, shape=(), dtype=float32)\n",
      "10 tf.Tensor(167.92758, shape=(), dtype=float32)\n",
      "end of epoch number:  2\n",
      "0 tf.Tensor(146.74341, shape=(), dtype=float32)\n",
      "1 tf.Tensor(183.56271, shape=(), dtype=float32)\n",
      "2 tf.Tensor(166.99733, shape=(), dtype=float32)\n",
      "3 tf.Tensor(160.55492, shape=(), dtype=float32)\n",
      "4 tf.Tensor(148.63492, shape=(), dtype=float32)\n",
      "5 tf.Tensor(142.46318, shape=(), dtype=float32)\n",
      "6 tf.Tensor(139.70789, shape=(), dtype=float32)\n",
      "7 tf.Tensor(138.7944, shape=(), dtype=float32)\n",
      "8 tf.Tensor(153.8933, shape=(), dtype=float32)\n",
      "9 tf.Tensor(158.18968, shape=(), dtype=float32)\n",
      "10 tf.Tensor(173.07826, shape=(), dtype=float32)\n",
      "end of epoch number:  3\n"
     ]
    }
   ],
   "source": [
    "#attempts at building the training loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds_gen):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_weights)\n",
    "            #x_batch, y_batch = tf.convert_to_tensor(x_batch, dtype = tf.double), tf.convert_to_tensor(y_batch)\n",
    "            logits = model(x_batch, training = True)\n",
    "            loss_value = tf.convert_to_tensor(hdepp_loss(logits, y_batch, reference_tensor))\n",
    "            #loss_value = tf.convert_to_tensor([[44, 44, 44], [3, 3, 3], [4, 5, 6]])\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(list(zip(grads, model.trainable_weights)))\n",
    "        #for gw in zip(grads, model.trainable_weights):\n",
    "        #    optimizer.apply_gradients(gw)\n",
    "        print(step, loss_value)\n",
    "    print('end of epoch number: ', epoch + 1)\n",
    "\n",
    "#, unconnected_gradients=tf.UnconnectedGradients.ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "469b34e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1d/kernel:0' shape=(1, 4, 8) dtype=float32, numpy=\n",
       " array([[[-0.09017699,  0.36037523,  0.11180694,  0.6894243 ,\n",
       "           0.5377504 , -0.4244084 ,  0.1726593 , -0.26267073],\n",
       "         [-0.07597645, -0.3083761 , -0.24398322,  0.06420318,\n",
       "           0.26304543,  0.00596339, -0.61467975, -0.33180973],\n",
       "         [ 0.20418522, -0.2497923 ,  0.6676156 , -0.59906507,\n",
       "           0.6373864 , -0.5226736 , -0.6799859 , -0.6513256 ],\n",
       "         [-0.5742302 ,  0.25197747,  0.04356371, -0.30002183,\n",
       "          -0.28581396,  0.44504076,  0.22720309, -0.5743715 ]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'conv1d/bias:0' shape=(8,) dtype=float32, numpy=\n",
       " array([ 0.00868391, -0.00255422, -0.0030806 , -0.00313172,  0.00234343,\n",
       "         0.00618256,  0.0014993 ,  0.00690097], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_1/kernel:0' shape=(5, 8, 3) dtype=float32, numpy=\n",
       " array([[[ 0.02610262,  0.03965794,  0.062293  ],\n",
       "         [-0.04267288,  0.25595897, -0.19214676],\n",
       "         [ 0.1531419 ,  0.1140961 , -0.12506172],\n",
       "         [-0.04325375, -0.0927493 , -0.02116816],\n",
       "         [ 0.23658684,  0.06610411,  0.29939464],\n",
       "         [ 0.1945714 ,  0.10163222,  0.3043314 ],\n",
       "         [ 0.0235935 ,  0.02414564, -0.03320918],\n",
       "         [-0.26318294, -0.12393947,  0.272772  ]],\n",
       " \n",
       "        [[ 0.19821219,  0.24657193,  0.27175957],\n",
       "         [-0.1158376 , -0.19573922, -0.19778761],\n",
       "         [-0.3085004 ,  0.01339745, -0.31496772],\n",
       "         [-0.30013558, -0.13438532, -0.05875187],\n",
       "         [-0.10148042, -0.25735444,  0.3134911 ],\n",
       "         [ 0.09866615,  0.09912353, -0.27861923],\n",
       "         [-0.23254128, -0.28958708,  0.07978953],\n",
       "         [ 0.27717328, -0.06978762,  0.18694602]],\n",
       " \n",
       "        [[ 0.22201262,  0.12888001, -0.10067412],\n",
       "         [ 0.00278348, -0.32758144,  0.14042406],\n",
       "         [-0.01273154,  0.06503416,  0.14794268],\n",
       "         [-0.10741242,  0.32638785,  0.2609725 ],\n",
       "         [ 0.24631348, -0.3017542 ,  0.08372239],\n",
       "         [ 0.08256487,  0.15601507,  0.14071293],\n",
       "         [-0.31087664,  0.32995266,  0.2112686 ],\n",
       "         [ 0.18700524,  0.10942195, -0.3110232 ]],\n",
       " \n",
       "        [[ 0.18507046, -0.26776552,  0.3215596 ],\n",
       "         [ 0.25492615,  0.07177371, -0.21110691],\n",
       "         [ 0.02948385, -0.16224797,  0.0034247 ],\n",
       "         [ 0.03120381, -0.29758784, -0.2098074 ],\n",
       "         [ 0.3080959 , -0.1949515 , -0.02395624],\n",
       "         [ 0.1515001 , -0.2326403 ,  0.16991256],\n",
       "         [ 0.25096893,  0.21850045, -0.09660501],\n",
       "         [ 0.09653595,  0.06633832,  0.14643928]],\n",
       " \n",
       "        [[ 0.22524273, -0.03095557,  0.1224464 ],\n",
       "         [-0.0085652 ,  0.10601386,  0.04360432],\n",
       "         [-0.19467056, -0.03404981,  0.03039582],\n",
       "         [ 0.3246318 ,  0.03036558, -0.25008208],\n",
       "         [-0.30708453,  0.31726304, -0.16597046],\n",
       "         [ 0.2859489 , -0.2590231 ,  0.22294739],\n",
       "         [-0.18737537, -0.02122968,  0.17989738],\n",
       "         [ 0.3234671 ,  0.26793954,  0.11673735]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_1/bias:0' shape=(3,) dtype=float32, numpy=array([0.0046979 , 0.00641652, 0.00576006], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/kernel:0' shape=(5, 3, 2) dtype=float32, numpy=\n",
       " array([[[ 0.27391994, -0.38208124],\n",
       "         [-0.3973513 ,  0.47482985],\n",
       "         [ 0.03875718, -0.41456363]],\n",
       " \n",
       "        [[-0.20120598, -0.44725648],\n",
       "         [ 0.26716563,  0.11420228],\n",
       "         [-0.22487944,  0.2246429 ]],\n",
       " \n",
       "        [[-0.14987116,  0.11392464],\n",
       "         [ 0.3162996 ,  0.39665532],\n",
       "         [-0.03294628, -0.01679004]],\n",
       " \n",
       "        [[-0.35719454,  0.20526364],\n",
       "         [-0.00552267,  0.22698887],\n",
       "         [-0.09228872, -0.3633069 ]],\n",
       " \n",
       "        [[-0.21584442,  0.26592755],\n",
       "         [-0.16134593, -0.05378691],\n",
       "         [-0.41829008,  0.38336822]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/bias:0' shape=(2,) dtype=float32, numpy=array([-0.00930169,  0.00569133], dtype=float32)>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca5502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
