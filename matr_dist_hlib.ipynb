{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d5f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import Phylo\n",
    "from Bio import AlignIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "import pylab\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import pygraphviz as pgv\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx import all_pairs_shortest_path_length\n",
    "import hyperlib\n",
    "from hyperlib.embedding.treerep import treerep\n",
    "from hyperlib.embedding.sarkar import sarkar_embedding\n",
    "from hyperlib.utils.multiprecision import poincare_dist\n",
    "from hyperlib.utils.multiprecision import poincare_reflect0\n",
    "#from hyperlib.manifold.lorentz import Lorentz\n",
    "#from hyperlib.manifold.poincare import Poincare\n",
    "import mpmath as mpm\n",
    "from scipy.special import expit\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c689f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './205_na_aln.fa'\n",
    "file_format = 'fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a767ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = AlignIO.read(file_name, file_format)\n",
    "#print(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2874c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i:seq.id for i, seq in enumerate(aln)}\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln_lenght = aln.get_alignment_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77edd20",
   "metadata": {},
   "source": [
    "sotto il modulo treeconstruction di Phylo c'è questo DistanceCalculator che calcola automaticamente le distanze secondo un modello dato come input, 'identity' di default.\n",
    "il metodo get_distance produce un oggetto di tipo DistanceMatrix, che va quindi converito con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dcfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Phylo.TreeConstruction.DistanceMatrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = DistanceCalculator('trans')\n",
    "dm = calc.get_distance(aln)\n",
    "#print(dm)\n",
    "type(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602de307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.array(dm)\n",
    "#dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8687d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = DistanceTreeConstructor()\n",
    "ptree = constructor.upgma(dm)\n",
    "ptree.ladderize()\n",
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8c3d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2461848b400>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree = treerep(dist_mat,return_networkx = True, tol = 0.0000000000000000000000001)\n",
    "htree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7208ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699f739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesi_aggiornati = [(edge[0], edge[1], {'weight' : expit(htree.get_edge_data(edge[0], edge[1])['weight'])}) for edge in list(htree.edges)]\n",
    "#pesi_aggiornati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cd360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pesi_aggiornati:\n",
    "    htree.update([i])\n",
    "htree.get_edge_data(4, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b29ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({33: {'weight': 0.5}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4941e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "htgraph = nx.nx_agraph.to_agraph(htree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8315c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#htgraph.layout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678adb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htgtwopi = htgraph\n",
    "htgtwopi.layout(prog = 'twopi') #dot, neato\n",
    "#htgtwopi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831659dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 224 nodes and 223 edges\n"
     ]
    }
   ],
   "source": [
    "print(htree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd9d2b",
   "metadata": {},
   "source": [
    "Infine il codice suggerito nell'esempio della libreria su github che dovrebbe fare l'embedding iperbolico nella sfera di Poincaré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4798b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('182.3930140184730296830577818620853629355128624706745952553613730108328677888921117463192282011772899928295324397826630587037104171664147009266325151865162568555755224573700242316251616213378906730657917555326376907130667781711161946561635505501557502749903012449283476284226224131427363125102892699180013462569534431948250584')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 0 # label of root node\n",
    "tau = 0.2 # scaling factor for edges\n",
    "embed_2D = sarkar_embedding(htree, root)\n",
    "\n",
    "# calculate hyperbolic distances from the embedding\n",
    "poincare_dist(embed_2D[0,:], embed_2D[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927924e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#embed_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67aaa18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix(\n",
       "[['-0.000003423767373985497984751829356124747085063760477591075834961990692450826259296341224306019947944315079684713212979073356493723219441847436171787303741494917810710510838979120572783480491943591745672352197053777428079487765954959897686032287107621031035249424852628182889140779419344143473784514951479874114276130901639076456', '0.005231774456298183848868269141325044776261945825202421062376019137696801914050044753010894185013976064400681042387321046914197558385284662849526699172849311596174751965364629275793968615729134769901644605393966053989845375783867845587629778476655030500633610682487087931944236830809385226817972148091128030929594756482837622']])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_2D[2, :] - embed_2D[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35341",
   "metadata": {},
   "source": [
    "# **Codice di preparazione per H-depp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825a0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f17fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import DataGenerator\n",
    "from src.loss_function import hdepp_loss_couple\n",
    "from src.loss_function import hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b026d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_nodes = len(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7958a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dist = dict(all_pairs_shortest_path_length(htree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83854bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_tensor = tf.convert_to_tensor([[tree_dist[i][j] for j in range(0, original_nodes)] for i in range(0, original_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d758b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([205, 205])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cddb904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad1523",
   "metadata": {},
   "source": [
    "**Distortions of the old embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "251d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('183.5706887125437275012669761316737293472617396839872234836643717924866364940717333990487804252432743470169131907996470112513843975258455353536347153842456837294554564308593777892772591629778012512753187676099243081539128496201698145316497961309813613126520098908361853240154806379715122640915085424493210542363988208267386476')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dist = {}\n",
    "\n",
    "#note that i use poincare_dist to calculate the embeddings distance\n",
    "#we might want to calculate it differently\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = poincare_dist(embed_2D[i,:], embed_2D[j,:])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    emb_dist[inode] = temp_dict\n",
    "\n",
    "emb_dist[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1d8617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_func(e_dist, t_dist):\n",
    "    if (t_dist != 0):\n",
    "        return np.square(( e_dist / t_dist ) - 1) \n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b0597d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('4.95021677894868878817336334564908546740134272664065431651070898600347645811634249429357125024968430692939913138850955383342030083736693737043879145601905638699703476019557666213811223948491572384014138730421419884895025299168795358490885744883002682359412122892913711795255528735768967170928689282513655583160863458363731869')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortion = {}\n",
    "\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = distortion_func(emb_dist[i][j], tree_dist[i][j])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    distortion[inode] = temp_dict\n",
    "    \n",
    "distortion[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de77ff8",
   "metadata": {},
   "source": [
    "**Encoding the sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "458e3c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATGAGCCAAGAAGAAAAGTTACCAAAGATTCTGATCGTTGAAGACGACGAGCGT...TTG')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln[0].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "182ba07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_dict = {'A' : np.array([0, 0, 0, 1]),\n",
    "           'T' : np.array([0, 0, 1, 0]),\n",
    "           'G' : np.array([0, 1, 0, 0]),\n",
    "           'C' : np.array([1, 0, 0, 0]),\n",
    "           '-' : np.array([0, 0, 0, 0]),}\n",
    "hot_dict[aln[0].seq[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48ba949e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_seqs = [np.array([hot_dict[car] for car in alignment.seq]) for alignment in aln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67c6fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = [[(encoded_seqs[i], encoded_seqs[j], tree_dist[i][j]) for j in tree_dist[i] if j < original_nodes] for i in tree_dist if i < original_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945eed7",
   "metadata": {},
   "source": [
    "**Train and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03eadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_IDs_train = [[i, j] for j in range(0, 22) for i in range(0, 22)]\n",
    "#lista_IDs_val = [[i, j] for j in range(22, 29) for i in range(22, 29)] #what should I use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8de4ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_train = [i for i in range(0, original_nodes-30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047b1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_val = [i for i in range(original_nodes-30, original_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cca52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (aln_lenght, ),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': 714, #shouldn't be categorical\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "#da correggere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54667860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_gen = DataGenerator(lista_IDs_train, model_inputs, **params)\n",
    "test_ds_gen = DataGenerator(lista_IDs_val, model_inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc5ed9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fcdf2bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\\n    #sparse vs non sparse\\n)\\n\\nmodel.fit(\\n    train_ds_gen,\\n    epochs=9,\\n    validation_data = test_ds_gen\\n)\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(714, 4)),\n",
    "    #tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Embedding(16, 2)\n",
    "    #tf.keras.layers.Dense(10)\n",
    "])\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    "    #sparse vs non sparse\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds_gen,\n",
    "    epochs=9,\n",
    "    validation_data = test_ds_gen\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "821593a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=3e-3)\n",
    "loss_fn = hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fde855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(236.32298, shape=(), dtype=float32)\n",
      "1 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "2 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "3 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "5 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "6 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "7 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "8 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "9 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "10 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "end of epoch number:  1\n",
      "0 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "1 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "2 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "3 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "5 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "6 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "7 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "8 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "9 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "10 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "end of epoch number:  2\n",
      "0 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "1 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "2 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "3 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "5 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "6 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "7 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "8 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "9 tf.Tensor(nan, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'embedding' (type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[15,0] = -2147483648 is not in [0, 16) [Op:ResourceGather]\n\nCall arguments received by layer 'embedding' (type Embedding):\n  • inputs=tf.Tensor(shape=(16, 2856), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m tape\u001b[38;5;241m.\u001b[39mwatch(model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[0;32m      9\u001b[0m x_batch, y_batch \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x_batch, dtype \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdouble), tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_batch)\n\u001b[1;32m---> 10\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(hdepp_loss(logits, y_batch, reference_tensor))\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#loss_value = tf.convert_to_tensor([[44, 44, 44], [3, 3, 3], [4, 5, 6]])\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7215\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7214\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7215\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'embedding' (type Embedding).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[15,0] = -2147483648 is not in [0, 16) [Op:ResourceGather]\n\nCall arguments received by layer 'embedding' (type Embedding):\n  • inputs=tf.Tensor(shape=(16, 2856), dtype=float32)"
     ]
    }
   ],
   "source": [
    "#attempts at building the training loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds_gen):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_weights)\n",
    "            x_batch, y_batch = tf.convert_to_tensor(x_batch, dtype = tf.double), tf.convert_to_tensor(y_batch)\n",
    "            logits = model(x_batch, training = True)\n",
    "            loss_value = tf.convert_to_tensor(hdepp_loss(logits, y_batch, reference_tensor))\n",
    "            #loss_value = tf.convert_to_tensor([[44, 44, 44], [3, 3, 3], [4, 5, 6]])\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        print(step, loss_value)\n",
    "    print('end of epoch number: ', epoch + 1)\n",
    "\n",
    "#, unconnected_gradients=tf.UnconnectedGradients.ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b7a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.acosh(tf.convert_to_tensor(149.22222))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d8be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
