{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d5f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import Phylo\n",
    "from Bio import AlignIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "import pylab\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import pygraphviz as pgv\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx import all_pairs_shortest_path_length\n",
    "import hyperlib\n",
    "from hyperlib.embedding.treerep import treerep\n",
    "from hyperlib.embedding.sarkar import sarkar_embedding\n",
    "from hyperlib.utils.multiprecision import poincare_dist\n",
    "from hyperlib.utils.multiprecision import poincare_reflect0\n",
    "#from hyperlib.manifold.lorentz import Lorentz\n",
    "#from hyperlib.manifold.poincare import Poincare\n",
    "import mpmath as mpm\n",
    "from scipy.special import expit\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c689f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './205_na_aln.fa'\n",
    "file_format = 'fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a767ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = AlignIO.read(file_name, file_format)\n",
    "#print(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2874c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i:seq.id for i, seq in enumerate(aln)}\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln_length = aln.get_alignment_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77edd20",
   "metadata": {},
   "source": [
    "sotto il modulo treeconstruction di Phylo c'è questo DistanceCalculator che calcola automaticamente le distanze secondo un modello dato come input, 'identity' di default.\n",
    "il metodo get_distance produce un oggetto di tipo DistanceMatrix, che va quindi converito con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dcfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Phylo.TreeConstruction.DistanceMatrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = DistanceCalculator('trans')\n",
    "dm = calc.get_distance(aln)\n",
    "#print(dm)\n",
    "type(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602de307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.array(dm)\n",
    "#dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8687d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = DistanceTreeConstructor()\n",
    "ptree = constructor.upgma(dm)\n",
    "ptree.ladderize()\n",
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8c3d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x260b5434f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree = treerep(dist_mat,return_networkx = True, tol = 0.0000000000000000000000001)\n",
    "htree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7208ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699f739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesi_aggiornati = [(edge[0], edge[1], {'weight' : expit(htree.get_edge_data(edge[0], edge[1])['weight'])}) for edge in list(htree.edges)]\n",
    "#pesi_aggiornati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cd360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pesi_aggiornati:\n",
    "    htree.update([i])\n",
    "htree.get_edge_data(4, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b29ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({33: {'weight': 0.5}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4941e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "htgraph = nx.nx_agraph.to_agraph(htree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8315c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#htgraph.layout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678adb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htgtwopi = htgraph\n",
    "htgtwopi.layout(prog = 'twopi') #dot, neato\n",
    "#htgtwopi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831659dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 224 nodes and 223 edges\n"
     ]
    }
   ],
   "source": [
    "print(htree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd9d2b",
   "metadata": {},
   "source": [
    "Infine il codice suggerito nell'esempio della libreria su github che dovrebbe fare l'embedding iperbolico nella sfera di Poincaré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4798b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('182.3930140184730296830577818620853629355128624706745952553613730108328677888921117463192282011772899928295324397826630587037104171664147009266325151865162568555755224573700242316251616213378906730657917555326376907130667781711161946561635505501557502749903012449283476284226224131427363125102892699180013462569534431948250584')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 0 # label of root node\n",
    "tau = 0.2 # scaling factor for edges\n",
    "embed_2D = sarkar_embedding(htree, root)\n",
    "\n",
    "# calculate hyperbolic distances from the embedding\n",
    "poincare_dist(embed_2D[0,:], embed_2D[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927924e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#embed_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67aaa18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix(\n",
       "[['-0.000003423767373985497984751829356124747085063760477591075834961990692450826259296341224306019947944315079684713212979073356493723219441847436171787303741494917810710510838979120572783480491943591745672352197053777428079487765954959897686032287107621031035249424852628182889140779419344143473784514951479874114276130901639076456', '0.005231774456298183848868269141325044776261945825202421062376019137696801914050044753010894185013976064400681042387321046914197558385284662849526699172849311596174751965364629275793968615729134769901644605393966053989845375783867845587629778476655030500633610682487087931944236830809385226817972148091128030929594756482837622']])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_2D[2, :] - embed_2D[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35341",
   "metadata": {},
   "source": [
    "# **Codice di preparazione per H-depp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825a0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f17fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import DataGenerator\n",
    "from src.loss_function import hdepp_loss_couple\n",
    "from src.loss_function import hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b026d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_nodes = len(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7958a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dist = dict(all_pairs_shortest_path_length(htree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83854bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_tensor = tf.convert_to_tensor([[tree_dist[i][j] for j in range(0, original_nodes)] for i in range(0, original_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d758b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([205, 205])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cddb904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad1523",
   "metadata": {},
   "source": [
    "**Distortions of the old embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "251d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('183.5706887125437275012669761316737293472617396839872234836643717924866364940717333990487804252432743470169131907996470112513843975258455353536347153842456837294554564308593777892772591629778012512753187676099243081539128496201698145316497961309813613126520098908361853240154806379715122640915085424493210542363988208267386476')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dist = {}\n",
    "\n",
    "#note that i use poincare_dist to calculate the embeddings distance\n",
    "#we might want to calculate it differently\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = poincare_dist(embed_2D[i,:], embed_2D[j,:])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    emb_dist[inode] = temp_dict\n",
    "\n",
    "emb_dist[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1d8617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_func(e_dist, t_dist):\n",
    "    if (t_dist != 0):\n",
    "        return np.square(( e_dist / t_dist ) - 1) \n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b0597d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('4.95021677894868878817336334564908546740134272664065431651070898600347645811634249429357125024968430692939913138850955383342030083736693737043879145601905638699703476019557666213811223948491572384014138730421419884895025299168795358490885744883002682359412122892913711795255528735768967170928689282513655583160863458363731869')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortion = {}\n",
    "\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = distortion_func(emb_dist[i][j], tree_dist[i][j])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    distortion[inode] = temp_dict\n",
    "    \n",
    "distortion[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de77ff8",
   "metadata": {},
   "source": [
    "**Encoding the sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "458e3c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATGAGCCAAGAAGAAAAGTTACCAAAGATTCTGATCGTTGAAGACGACGAGCGT...TTG')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln[0].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "182ba07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_dict = {'A' : np.array([0, 0, 0, 1]),\n",
    "           'T' : np.array([0, 0, 1, 0]),\n",
    "           'G' : np.array([0, 1, 0, 0]),\n",
    "           'C' : np.array([1, 0, 0, 0]),\n",
    "           '-' : np.array([0, 0, 0, 0]),}\n",
    "hot_dict[aln[0].seq[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48ba949e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_seqs = [np.array([hot_dict[car] for car in alignment.seq]) for alignment in aln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67c6fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = [[(encoded_seqs[i], encoded_seqs[j], tree_dist[i][j]) for j in tree_dist[i] if j < original_nodes] for i in tree_dist if i < original_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945eed7",
   "metadata": {},
   "source": [
    "**Train and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03eadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_IDs_train = [[i, j] for j in range(0, 22) for i in range(0, 22)]\n",
    "#lista_IDs_val = [[i, j] for j in range(22, 29) for i in range(22, 29)] #what should I use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8de4ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_train = [i for i in range(0, original_nodes-30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "047b1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_val = [i for i in range(original_nodes-30, original_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cca52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (aln_length, ),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': aln_length, #shouldn't be categorical\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "#da correggere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54667860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_gen = DataGenerator(lista_IDs_train, model_inputs, **params)\n",
    "test_ds_gen = DataGenerator(lista_IDs_val, model_inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c49f587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperlib.nn.layers.lin_hyp import LinearHyperbolic\n",
    "from hyperlib.nn.optimizers.rsgd import RSGD\n",
    "from hyperlib.manifold.poincare import Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50c1c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc5ed9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.Input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "821593a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=3e-3)\n",
    "#optimizer = RSGD(learning_rate = 0.1)\n",
    "loss_fn = hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33285aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearHyperbolic??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "456012e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(4).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcdf2bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\\n    #sparse vs non sparse\\n)\\n\\nmodel.fit(\\n    train_ds_gen,\\n    epochs=9,\\n    validation_data = test_ds_gen\\n)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Flatten(input_shape=(714, 4)),\n",
    "    tf.keras.Input((714, 4), 16),\n",
    "    tf.keras.layers.Conv1D(3, 1),\n",
    "    tf.keras.layers.Conv1D(3, 5),\n",
    "    tf.keras.layers.Conv1D(3, 5),\n",
    "    LinearHyperbolic(10, Poincare(), 1)\n",
    "    #LinearHyperbolic(10, Poincare(), 1)\n",
    "    #tf.keras.layers.Dense(10)\n",
    "])\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    "    #sparse vs non sparse\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds_gen,\n",
    "    epochs=9,\n",
    "    validation_data = test_ds_gen\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fde855d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tf.Tensor(223.77580203402087, shape=(), dtype=float64)\n",
      "1 tf.Tensor(192.79281780865108, shape=(), dtype=float64)\n",
      "2 tf.Tensor(196.75635037432278, shape=(), dtype=float64)\n",
      "3 tf.Tensor(211.57047869728032, shape=(), dtype=float64)\n",
      "4 tf.Tensor(200.32887138483798, shape=(), dtype=float64)\n",
      "5 tf.Tensor(188.4432711189567, shape=(), dtype=float64)\n",
      "6 tf.Tensor(192.32202150061923, shape=(), dtype=float64)\n",
      "7 tf.Tensor(151.90633376057718, shape=(), dtype=float64)\n",
      "8 tf.Tensor(165.5859901983232, shape=(), dtype=float64)\n",
      "9 tf.Tensor(193.08038211895558, shape=(), dtype=float64)\n",
      "10 tf.Tensor(151.63972542098344, shape=(), dtype=float64)\n",
      "end of epoch number:  1\n",
      "0 tf.Tensor(181.8875312637238, shape=(), dtype=float64)\n",
      "1 tf.Tensor(137.46987873666203, shape=(), dtype=float64)\n",
      "2 tf.Tensor(180.45931516884488, shape=(), dtype=float64)\n",
      "3 tf.Tensor(187.27047664690306, shape=(), dtype=float64)\n",
      "4 tf.Tensor(160.79601732168194, shape=(), dtype=float64)\n",
      "5 tf.Tensor(177.11486864115824, shape=(), dtype=float64)\n",
      "6 tf.Tensor(175.08402183249564, shape=(), dtype=float64)\n",
      "7 tf.Tensor(139.1786621155854, shape=(), dtype=float64)\n",
      "8 tf.Tensor(157.5185367020548, shape=(), dtype=float64)\n",
      "9 tf.Tensor(187.10431501910605, shape=(), dtype=float64)\n",
      "10 tf.Tensor(167.39840062115908, shape=(), dtype=float64)\n",
      "end of epoch number:  2\n",
      "0 tf.Tensor(183.17648235055103, shape=(), dtype=float64)\n",
      "1 tf.Tensor(151.1867514009815, shape=(), dtype=float64)\n",
      "2 tf.Tensor(198.47391756483083, shape=(), dtype=float64)\n",
      "3 tf.Tensor(194.472143404265, shape=(), dtype=float64)\n",
      "4 tf.Tensor(161.77219367310948, shape=(), dtype=float64)\n",
      "5 tf.Tensor(179.8030282533343, shape=(), dtype=float64)\n",
      "6 tf.Tensor(176.87347933011324, shape=(), dtype=float64)\n",
      "7 tf.Tensor(138.32222692953334, shape=(), dtype=float64)\n",
      "8 tf.Tensor(157.25035884677794, shape=(), dtype=float64)\n",
      "9 tf.Tensor(186.5705014142753, shape=(), dtype=float64)\n",
      "10 tf.Tensor(166.67412803189876, shape=(), dtype=float64)\n",
      "end of epoch number:  3\n"
     ]
    }
   ],
   "source": [
    "#attempts at building the training loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds_gen):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_weights)\n",
    "            x_batch, y_batch = tf.convert_to_tensor(x_batch, dtype = tf.double), tf.convert_to_tensor(y_batch)\n",
    "            logits = model(x_batch, training = True)\n",
    "            loss_value = tf.convert_to_tensor(hdepp_loss(logits, y_batch, reference_tensor))\n",
    "            #loss_value = tf.convert_to_tensor([[44, 44, 44], [3, 3, 3], [4, 5, 6]])\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        print(step, loss_value)\n",
    "    print('end of epoch number: ', epoch + 1)\n",
    "\n",
    "#, unconnected_gradients=tf.UnconnectedGradients.ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af87b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.layers.Conv1D??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bd4b7a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1d/kernel:0' shape=(1, 4, 3) dtype=float32, numpy=\n",
       " array([[[-1.1476644 , -0.29755005, -0.43258002],\n",
       "         [-0.3865747 , -0.3853055 ,  0.77212805],\n",
       "         [ 0.71155876,  0.4271341 , -0.36215177],\n",
       "         [-0.5580618 ,  0.33030763, -0.793786  ]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d/bias:0' shape=(3,) dtype=float32, numpy=array([-0.25906333, -0.11613213,  0.03736612], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_1/kernel:0' shape=(5, 3, 3) dtype=float32, numpy=\n",
       " array([[[ 0.63607556, -0.36562067,  0.60518014],\n",
       "         [-0.08769166, -0.24070396, -0.03188346],\n",
       "         [ 0.56178236, -0.57342273,  0.37864894]],\n",
       " \n",
       "        [[-0.05795952,  0.11792028, -0.77371603],\n",
       "         [-0.03623766, -0.09368475,  0.12387466],\n",
       "         [ 0.19956584,  0.18550605,  0.3120285 ]],\n",
       " \n",
       "        [[ 0.44838703, -0.32052466, -0.3990049 ],\n",
       "         [ 0.24874137, -0.16632235, -0.08323624],\n",
       "         [-0.22434044, -0.14907193, -0.04689869]],\n",
       " \n",
       "        [[-0.32688665, -0.17924373,  0.10465576],\n",
       "         [-0.20853618,  0.09878261,  0.40715697],\n",
       "         [-0.49657536, -0.12922779, -0.2143152 ]],\n",
       " \n",
       "        [[ 0.5626773 ,  0.18309355,  0.3920874 ],\n",
       "         [ 0.64353263, -0.5205035 ,  0.2505499 ],\n",
       "         [-0.54901   ,  0.50614464, -0.09400526]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_1/bias:0' shape=(3,) dtype=float32, numpy=array([-0.50405675, -0.0852512 , -0.11483711], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/kernel:0' shape=(5, 3, 3) dtype=float32, numpy=\n",
       " array([[[ 0.3101541 ,  0.3855619 ,  0.05042866],\n",
       "         [-0.4585575 ,  0.1513101 , -0.16859569],\n",
       "         [-0.08061861, -0.00367858,  0.39447728]],\n",
       " \n",
       "        [[-0.5771262 ,  0.09071101,  0.24442825],\n",
       "         [ 0.54162496,  0.01182379, -0.28517672],\n",
       "         [-0.61785024,  0.52702314, -0.5849821 ]],\n",
       " \n",
       "        [[ 0.3996555 ,  0.14909834,  0.6195119 ],\n",
       "         [ 0.09775489,  0.30604562,  0.19039333],\n",
       "         [ 0.18741362, -0.19219452,  0.45469046]],\n",
       " \n",
       "        [[-0.49031177,  0.01512953,  0.7039103 ],\n",
       "         [ 0.24687631,  0.25514224, -0.2656107 ],\n",
       "         [ 0.3807876 , -0.46734583,  0.28439543]],\n",
       " \n",
       "        [[-0.7145962 ,  0.5212715 ,  0.36138722],\n",
       "         [ 0.43966857, -0.16741988,  0.31192198],\n",
       "         [ 0.0859858 , -0.33050925, -0.01644899]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/bias:0' shape=(3,) dtype=float32, numpy=array([ 0.32666782, -0.11653756, -0.38207158], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(1,) dtype=float64, numpy=array([0.72798464])>,\n",
       " <tf.Variable 'linear_hyperbolic/Variable:0' shape=(3, 10) dtype=float64, numpy=\n",
       " array([[ 0.45631429, -0.25651195,  0.09543092,  0.10974952,  0.37782455,\n",
       "          0.0776277 ,  0.40701586,  0.11692575, -0.13701559, -0.00174195],\n",
       "        [-0.16221044,  0.10524868, -0.05278072,  0.01072323, -0.13177366,\n",
       "         -0.0671958 , -0.12032325, -0.02283752, -0.01684232,  0.04731629],\n",
       "        [ 0.18178627, -0.08760676,  0.01939227,  0.12090476,  0.14976038,\n",
       "         -0.01797732,  0.19468927,  0.0856865 , -0.14634203,  0.06173504]])>,\n",
       " <tf.Variable 'linear_hyperbolic/bias:0' shape=(10,) dtype=float64, numpy=\n",
       " array([-0.05302308,  0.05178769, -0.02779922, -0.01274486, -0.12376769,\n",
       "        -0.03329162, -0.05367291, -0.02427098, -0.06286938,  0.02062377])>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ce2a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.math.acosh(tf.convert_to_tensor( tf.math.acosh(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d8be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
