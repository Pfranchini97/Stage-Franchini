{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d5f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import Phylo\n",
    "from Bio import AlignIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "#import pylab\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "#import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import pygraphviz as pgv\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx import all_pairs_shortest_path_length\n",
    "import hyperlib\n",
    "from hyperlib.embedding.treerep import treerep\n",
    "from hyperlib.embedding.sarkar import sarkar_embedding\n",
    "from hyperlib.utils.multiprecision import poincare_dist\n",
    "from hyperlib.utils.multiprecision import poincare_reflect0\n",
    "#from hyperlib.manifold.lorentz import Lorentz\n",
    "#from hyperlib.manifold.poincare import Poincare\n",
    "import mpmath as mpm\n",
    "from scipy.special import expit\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c689f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './205_na_aln.fa'\n",
    "file_format = 'fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a767ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = AlignIO.read(file_name, file_format)\n",
    "#print(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2874c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i:seq.id for i, seq in enumerate(aln)}\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bdc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln_length = aln.get_alignment_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77edd20",
   "metadata": {},
   "source": [
    "sotto il modulo treeconstruction di Phylo c'è questo DistanceCalculator che calcola automaticamente le distanze secondo un modello dato come input, 'identity' di default.\n",
    "il metodo get_distance produce un oggetto di tipo DistanceMatrix, che va quindi converito con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13dcfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Phylo.TreeConstruction.DistanceMatrix"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = DistanceCalculator('trans')\n",
    "dm = calc.get_distance(aln)\n",
    "#print(dm)\n",
    "type(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602de307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.array(dm)\n",
    "#dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8687d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = DistanceTreeConstructor()\n",
    "ptree = constructor.upgma(dm)\n",
    "ptree.ladderize()\n",
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d8c3d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x2976f10d550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree = treerep(dist_mat,return_networkx = True, tol = 0.0000000000000000000000001)\n",
    "htree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7208ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "699f739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesi_aggiornati = [(edge[0], edge[1], {'weight' : expit(htree.get_edge_data(edge[0], edge[1])['weight'])}) for edge in list(htree.edges)]\n",
    "#pesi_aggiornati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12cd360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pesi_aggiornati:\n",
    "    htree.update([i])\n",
    "htree.get_edge_data(4, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b29ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({33: {'weight': 0.5}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4941e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "htgraph = nx.nx_agraph.to_agraph(htree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8315c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#htgraph.layout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "678adb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htgtwopi = htgraph\n",
    "htgtwopi.layout(prog = 'twopi') #dot, neato\n",
    "#htgtwopi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "831659dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 224 nodes and 223 edges\n"
     ]
    }
   ],
   "source": [
    "print(htree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd9d2b",
   "metadata": {},
   "source": [
    "Infine il codice suggerito nell'esempio della libreria su github che dovrebbe fare l'embedding iperbolico nella sfera di Poincaré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4798b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('182.3930140184730296830577818620853629355128624706745952553613730108328677888921117463192282011772899928295324397826630587037104171664147009266325151865162568555755224573700242316251616213378906730657917555326376907130667781711161946561635505501557502749903012449283476284226224131427363125102892699180013462569534431948250584')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 0 # label of root node\n",
    "tau = 0.2 # scaling factor for edges\n",
    "embed_2D = sarkar_embedding(htree, root)\n",
    "\n",
    "# calculate hyperbolic distances from the embedding\n",
    "poincare_dist(embed_2D[0,:], embed_2D[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927924e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#embed_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67aaa18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix(\n",
       "[['-0.000003423767373985497984751829356124747085063760477591075834961990692450826259296341224306019947944315079684713212979073356493723219441847436171787303741494917810710510838979120572783480491943591745672352197053777428079487765954959897686032287107621031035249424852628182889140779419344143473784514951479874114276130901639076456', '0.005231774456298183848868269141325044776261945825202421062376019137696801914050044753010894185013976064400681042387321046914197558385284662849526699172849311596174751965364629275793968615729134769901644605393966053989845375783867845587629778476655030500633610682487087931944236830809385226817972148091128030929594756482837622']])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_2D[2, :] - embed_2D[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35341",
   "metadata": {},
   "source": [
    "# **Codice di preparazione per H-depp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825a0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f17fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import DataGenerator\n",
    "from src.loss_function import hdepp_loss_couple\n",
    "from src.loss_function import hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "293aed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_riemopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b026d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_nodes = len(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7958a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dist = dict(all_pairs_shortest_path_length(htree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83854bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_tensor = tf.convert_to_tensor([[tree_dist[i][j] for j in range(0, original_nodes)] for i in range(0, original_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d758b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([205, 205])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cddb904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad1523",
   "metadata": {},
   "source": [
    "**Distortions of the old embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "251d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('183.5706887125437275012669761316737293472617396839872234836643717924866364940717333990487804252432743470169131907996470112513843975258455353536347153842456837294554564308593777892772591629778012512753187676099243081539128496201698145316497961309813613126520098908361853240154806379715122640915085424493210542363988208267386476')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dist = {}\n",
    "\n",
    "#note that i use poincare_dist to calculate the embeddings distance\n",
    "#we might want to calculate it differently\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = poincare_dist(embed_2D[i,:], embed_2D[j,:])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    emb_dist[inode] = temp_dict\n",
    "\n",
    "emb_dist[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1d8617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_func(e_dist, t_dist):\n",
    "    if (t_dist != 0):\n",
    "        return np.square(( e_dist / t_dist ) - 1) \n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11b0597d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('4.95021677894868878817336334564908546740134272664065431651070898600347645811634249429357125024968430692939913138850955383342030083736693737043879145601905638699703476019557666213811223948491572384014138730421419884895025299168795358490885744883002682359412122892913711795255528735768967170928689282513655583160863458363731869')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortion = {}\n",
    "\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = distortion_func(emb_dist[i][j], tree_dist[i][j])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    distortion[inode] = temp_dict\n",
    "    \n",
    "distortion[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de77ff8",
   "metadata": {},
   "source": [
    "**Encoding the sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "458e3c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATGAGCCAAGAAGAAAAGTTACCAAAGATTCTGATCGTTGAAGACGACGAGCGT...TTG')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln[0].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "182ba07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_dict = {'A' : np.array([0, 0, 0, 1]),\n",
    "           'T' : np.array([0, 0, 1, 0]),\n",
    "           'G' : np.array([0, 1, 0, 0]),\n",
    "           'C' : np.array([1, 0, 0, 0]),\n",
    "           '-' : np.array([0, 0, 0, 0]),}\n",
    "hot_dict[aln[0].seq[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48ba949e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_seqs = [np.array([hot_dict[car] for car in alignment.seq]) for alignment in aln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67c6fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = [[(encoded_seqs[i], encoded_seqs[j], tree_dist[i][j]) for j in tree_dist[i] if j < original_nodes] for i in tree_dist if i < original_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945eed7",
   "metadata": {},
   "source": [
    "**Train and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03eadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_IDs_train = [[i, j] for j in range(0, 22) for i in range(0, 22)]\n",
    "#lista_IDs_val = [[i, j] for j in range(22, 29) for i in range(22, 29)] #what should I use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8de4ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_train = [i for i in range(0, original_nodes-30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "047b1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_val = [i for i in range(original_nodes-30, original_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cca52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (aln_length, ),\n",
    "          'batch_size': 4,\n",
    "          'n_classes': aln_length, #shouldn't be categorical\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "#da correggere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54667860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_gen = DataGenerator(lista_IDs_train, model_inputs, **params)\n",
    "test_ds_gen = DataGenerator(lista_IDs_val, model_inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c49f587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperlib.nn.layers.lin_hyp import LinearHyperbolic\n",
    "from hyperlib.nn.optimizers.rsgd import RSGD\n",
    "from hyperlib.manifold.poincare import Poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50c1c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baee04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow_riemopt.optimizers.RiemannianSGD??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "821593a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = keras.optimizers.SGD(learning_rate=1e-9, clipnorm = 1.0, clipvalue = 0.5)\n",
    "#optimizer = RSGD(learning_rate = 0.1)\n",
    "optimizer = tensorflow_riemopt.optimizers.RiemannianSGD(learning_rate = 1e-18, clipnorm = 1.0, clipvalue = 0.5)\n",
    "loss_fn = hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "376d8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.layers.LSTM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fcdf2bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\\n    #sparse vs non sparse\\n)\\n\\nmodel.fit(\\n    train_ds_gen,\\n    epochs=9,\\n    validation_data = test_ds_gen\\n)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    #tf.keras.layers.Flatten(input_shape=(714, 4)),\n",
    "    tf.keras.Input((714, 4), 4),\n",
    "    \n",
    "    tf.keras.layers.Conv1D(8, 1, kernel_regularizer = 'L2'),\n",
    "    tf.keras.layers.Conv1D(3, 5, kernel_regularizer = 'L2'),\n",
    "    tf.keras.layers.Conv1D(2, 5, kernel_regularizer = 'L2'),\n",
    "    tf.keras.layers.LSTM(15)\n",
    "    #LinearHyperbolic(10, Poincare(), 1)\n",
    "    #tf.keras.layers.Dense(10)\n",
    "])\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    "    #sparse vs non sparse\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds_gen,\n",
    "    epochs=9,\n",
    "    validation_data = test_ds_gen\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37569f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer.apply_gradients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4fde855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function RiemannianSGD._resource_apply_dense at 0x00000297354DACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function RiemannianSGD._resource_apply_dense at 0x00000297354DACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0 tf.Tensor(12.0, shape=(), dtype=float32)\n",
      "1 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "2 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "3 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "5 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "6 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "7 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "8 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "9 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "10 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "11 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "12 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "13 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "14 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "15 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "16 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "17 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "18 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "19 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "20 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "21 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "22 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "23 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "24 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "25 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "26 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "27 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "28 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "29 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "30 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "31 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "32 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "33 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "34 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "35 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "36 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "37 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "38 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "39 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "40 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "41 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "42 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "43 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "end of epoch number:  1\n",
      "0 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "1 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "2 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "3 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "5 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "6 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "7 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "8 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "9 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "10 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "11 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "12 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "13 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "14 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "15 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "16 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "17 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "18 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "19 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "20 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "21 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "22 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "23 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "24 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "25 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "26 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "27 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "28 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "29 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "30 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "31 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "32 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "33 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "34 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "35 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "36 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "37 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "38 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "39 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "40 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "41 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "42 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "43 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "end of epoch number:  2\n",
      "0 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "1 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "2 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "3 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "4 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "5 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "6 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "7 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "8 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "9 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "10 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "11 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "12 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "13 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "14 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "15 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "16 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "17 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "18 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "19 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "20 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "21 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "22 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "23 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "24 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "25 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "26 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "27 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "28 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "29 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "30 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "31 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "32 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "33 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "34 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "35 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "36 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "37 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "38 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "39 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "40 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "41 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "42 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "43 tf.Tensor(nan, shape=(), dtype=float32)\n",
      "end of epoch number:  3\n"
     ]
    }
   ],
   "source": [
    "#attempts at building the training loop\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for step, (x_batch, y_batch) in enumerate(train_ds_gen):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(model.trainable_weights)\n",
    "            #x_batch, y_batch = tf.convert_to_tensor(x_batch, dtype = tf.double), tf.convert_to_tensor(y_batch)\n",
    "            logits = model(x_batch, training = True)\n",
    "            loss_value = tf.convert_to_tensor(hdepp_loss(logits, y_batch, reference_tensor))\n",
    "            #loss_value = tf.convert_to_tensor([[44, 44, 44], [3, 3, 3], [4, 5, 6]])\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(list(zip(grads, model.trainable_weights)))\n",
    "        #for gw in zip(grads, model.trainable_weights):\n",
    "        #    optimizer.apply_gradients(gw)\n",
    "        print(step, loss_value)\n",
    "    print('end of epoch number: ', epoch + 1)\n",
    "\n",
    "#, unconnected_gradients=tf.UnconnectedGradients.ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "469b34e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1d/kernel:0' shape=(1, 4, 8) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "         [nan, nan, nan, nan, nan, nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d/bias:0' shape=(8,) dtype=float32, numpy=array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_1/kernel:0' shape=(5, 8, 3) dtype=float32, numpy=\n",
       " array([[[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]],\n",
       " \n",
       "        [[nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan],\n",
       "         [nan, nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_1/bias:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/kernel:0' shape=(5, 3, 2) dtype=float32, numpy=\n",
       " array([[[nan, nan],\n",
       "         [nan, nan],\n",
       "         [nan, nan]],\n",
       " \n",
       "        [[nan, nan],\n",
       "         [nan, nan],\n",
       "         [nan, nan]],\n",
       " \n",
       "        [[nan, nan],\n",
       "         [nan, nan],\n",
       "         [nan, nan]],\n",
       " \n",
       "        [[nan, nan],\n",
       "         [nan, nan],\n",
       "         [nan, nan]],\n",
       " \n",
       "        [[nan, nan],\n",
       "         [nan, nan],\n",
       "         [nan, nan]]], dtype=float32)>,\n",
       " <tf.Variable 'conv1d_2/bias:0' shape=(2,) dtype=float32, numpy=array([nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'lstm/lstm_cell/kernel:0' shape=(2, 60) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'lstm/lstm_cell/recurrent_kernel:0' shape=(15, 60) dtype=float32, numpy=\n",
       " array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float32)>,\n",
       " <tf.Variable 'lstm/lstm_cell/bias:0' shape=(60,) dtype=float32, numpy=\n",
       " array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan], dtype=float32)>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca5502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
