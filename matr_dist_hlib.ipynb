{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d5f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio\n",
    "from Bio import Phylo\n",
    "from Bio import AlignIO\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "import pylab\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pydot\n",
    "import pygraphviz as pgv\n",
    "from networkx.drawing.nx_pydot import graphviz_layout\n",
    "from networkx import all_pairs_shortest_path_length\n",
    "import hyperlib\n",
    "from hyperlib.embedding.treerep import treerep\n",
    "from hyperlib.embedding.sarkar import sarkar_embedding\n",
    "from hyperlib.utils.multiprecision import poincare_dist\n",
    "from hyperlib.utils.multiprecision import poincare_reflect0\n",
    "#from hyperlib.manifold.lorentz import Lorentz\n",
    "#from hyperlib.manifold.poincare import Poincare\n",
    "import mpmath as mpm\n",
    "from scipy.special import expit\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dde4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hyperlib --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5717305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647cc11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install --channel conda-forge pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7b656df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c689f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './205_na_aln.fa'\n",
    "file_format = 'fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a767ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln = AlignIO.read(file_name, file_format)\n",
    "#print(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2874c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i:seq.id for i, seq in enumerate(aln)}\n",
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bdc965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln_lenght = aln.get_alignment_length()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77edd20",
   "metadata": {},
   "source": [
    "sotto il modulo treeconstruction di Phylo c'è questo DistanceCalculator che calcola automaticamente le distanze secondo un modello dato come input, 'identity' di default.\n",
    "il metodo get_distance produce un oggetto di tipo DistanceMatrix, che va quindi converito con numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13dcfd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bio.Phylo.TreeConstruction.DistanceMatrix"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc = DistanceCalculator('trans')\n",
    "dm = calc.get_distance(aln)\n",
    "#print(dm)\n",
    "type(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602de307",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = np.array(dm)\n",
    "#dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9315e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree = Phylo.read('strain_tree.nwk', 'newick')\n",
    "#tree.ladderize()\n",
    "#Phylo.draw(tree)\n",
    "#type(tree)\n",
    "#leaves = tree.get_terminals()\n",
    "#dist_mat = np.array([[tree.distance(leaf1, leaf2 ) for leaf2 in leaves] for leaf1 in leaves])\n",
    "#dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8687d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor = DistanceTreeConstructor()\n",
    "ptree = constructor.upgma(dm)\n",
    "ptree.ladderize()\n",
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d4772eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phylo.draw(ptree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d8c3d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x22f3d3a8940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree = treerep(dist_mat,return_networkx = True, tol = 0.0000000000000000000000001)\n",
    "htree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f7208ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "699f739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pesi_aggiornati = [(edge[0], edge[1], {'weight' : expit(htree.get_edge_data(edge[0], edge[1])['weight'])}) for edge in list(htree.edges)]\n",
    "#pesi_aggiornati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12cd360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pesi_aggiornati:\n",
    "    htree.update([i])\n",
    "htree.get_edge_data(4, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b29ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtlasView({33: {'weight': 0.5}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htree[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4941e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "htgraph = nx.nx_agraph.to_agraph(htree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8315c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#htgraph.layout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "678adb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "htgtwopi = htgraph\n",
    "htgtwopi.layout(prog = 'twopi') #dot, neato\n",
    "#htgtwopi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "831659dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 224 nodes and 223 edges\n"
     ]
    }
   ],
   "source": [
    "print(htree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd9d2b",
   "metadata": {},
   "source": [
    "Infine il codice suggerito nell'esempio della libreria su github che dovrebbe fare l'embedding iperbolico nella sfera di Poincaré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4798b65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('182.3930140184730296830577818620853629355128624706745952553613730108328677888921117463192282011772899928295324397826630587037104171664147009266325151865162568555755224573700242316251616213378906730657917555326376907130667781711161946561635505501557502749903012449283476284226224131427363125102892699180013462569534431948250584')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = 0 # label of root node\n",
    "tau = 0.2 # scaling factor for edges\n",
    "embed_2D = sarkar_embedding(htree, root)\n",
    "\n",
    "# calculate hyperbolic distances from the embedding\n",
    "poincare_dist(embed_2D[0,:], embed_2D[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "927924e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#embed_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67aaa18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix(\n",
       "[['-0.000003423767373985497984751829356124747085063760477591075834961990692450826259296341224306019947944315079684713212979073356493723219441847436171787303741494917810710510838979120572783480491943591745672352197053777428079487765954959897686032287107621031035249424852628182889140779419344143473784514951479874114276130901639076456', '0.005231774456298183848868269141325044776261945825202421062376019137696801914050044753010894185013976064400681042387321046914197558385284662849526699172849311596174751965364629275793968615729134769901644605393966053989845375783867845587629778476655030500633610682487087931944236830809385226817972148091128030929594756482837622']])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_2D[2, :] - embed_2D[1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc35341",
   "metadata": {},
   "source": [
    "# **Codice di preparazione per H-depp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "825a0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "\n",
    "module_path = str(Path.cwd().parents[0])\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69f17fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_generator import DataGenerator\n",
    "from src.loss_function import hdepp_loss_couple\n",
    "from src.loss_function import hdepp_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b026d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_nodes = len(aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7958a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dist = dict(all_pairs_shortest_path_length(htree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83854bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reference_tensor = tf.convert_to_tensor([[tree_dist[i][j] for j in range(0, original_nodes)] for i in range(0, original_nodes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d758b82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([205, 205])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_tensor.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad1523",
   "metadata": {},
   "source": [
    "**Distortions of the old embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "251d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('183.5706887125437275012669761316737293472617396839872234836643717924866364940717333990487804252432743470169131907996470112513843975258455353536347153842456837294554564308593777892772591629778012512753187676099243081539128496201698145316497961309813613126520098908361853240154806379715122640915085424493210542363988208267386476')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dist = {}\n",
    "\n",
    "#note that i use poincare_dist to calculate the embeddings distance\n",
    "#we might want to calculate it differently\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = poincare_dist(embed_2D[i,:], embed_2D[j,:])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    emb_dist[inode] = temp_dict\n",
    "\n",
    "emb_dist[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1d8617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distortion_func(e_dist, t_dist):\n",
    "    if (t_dist != 0):\n",
    "        return np.square(( e_dist / t_dist ) - 1) \n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11b0597d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpf('4.95021677894868878817336334564908546740134272664065431651070898600347645811634249429357125024968430692939913138850955383342030083736693737043879145601905638699703476019557666213811223948491572384014138730421419884895025299168795358490885744883002682359412122892913711795255528735768967170928689282513655583160863458363731869')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distortion = {}\n",
    "\n",
    "for i in range (0, embed_2D.rows):\n",
    "    temp_dict = {}\n",
    "    for j in range (0, embed_2D.rows):\n",
    "        jnode = list(htree.nodes)[j]\n",
    "        temp_dict[jnode] = distortion_func(emb_dist[i][j], tree_dist[i][j])\n",
    "    inode = list(htree.nodes)[i]\n",
    "    distortion[inode] = temp_dict\n",
    "    \n",
    "distortion[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de77ff8",
   "metadata": {},
   "source": [
    "**Encoding the sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "458e3c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('ATGAGCCAAGAAGAAAAGTTACCAAAGATTCTGATCGTTGAAGACGACGAGCGT...TTG')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aln[0].seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "182ba07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_dict = {'A' : np.array([0, 0, 0, 1]),\n",
    "           'T' : np.array([0, 0, 1, 0]),\n",
    "           'G' : np.array([0, 1, 0, 0]),\n",
    "           'C' : np.array([1, 0, 0, 0]),\n",
    "           '-' : np.array([0, 0, 0, 0]),}\n",
    "hot_dict[aln[0].seq[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48ba949e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_seqs = [np.array([hot_dict[car] for car in alignment.seq]) for alignment in aln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67c6fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = [[(encoded_seqs[i], encoded_seqs[j], tree_dist[i][j]) for j in tree_dist[i] if j < original_nodes] for i in tree_dist if i < original_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945eed7",
   "metadata": {},
   "source": [
    "**Train and validation sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03eadff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_IDs_train = [[i, j] for j in range(0, 22) for i in range(0, 22)]\n",
    "#lista_IDs_val = [[i, j] for j in range(22, 29) for i in range(22, 29)] #what should I use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8de4ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_train = [i for i in range(0, original_nodes-30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "047b1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_IDs_val = [i for i in range(original_nodes-30, original_nodes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5cca52c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (aln_lenght, ),\n",
    "          'batch_size': 16,\n",
    "          'n_classes': 714, #shouldn't be categorical\n",
    "          'n_channels': 4,\n",
    "          'shuffle': True}\n",
    "#da correggere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54667860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_gen = DataGenerator(lista_IDs_train, model_inputs, **params)\n",
    "test_ds_gen = DataGenerator(lista_IDs_val, model_inputs, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc5ed9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iteratore = iter(train_ds_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fcdf2bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\\n    metrics=[tf.keras.metrics.CategoricalAccuracy()],\\n    #sparse vs non sparse\\n)\\n\\nmodel.fit(\\n    train_ds_gen,\\n    epochs=9,\\n    validation_data = test_ds_gen\\n)\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(714, 4)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Embedding(32, 2)\n",
    "    #tf.keras.layers.Dense(10)\n",
    "])\n",
    "'''\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
    "    #sparse vs non sparse\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_ds_gen,\n",
    "    epochs=9,\n",
    "    validation_data = test_ds_gen\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4fde855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[92], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m hdepp_loss(logits, y_pos, reference_tensor)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#loss_value = keras.losses.SparseCategoricalCrossentropy(from_logits = True)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model\u001b[38;5;241m.\u001b[39mtrainable_weights))\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(step, loss_value)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1106\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1107\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1108\u001b[0m           output_gradients))\n\u001b[0;32m   1109\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1110\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1112\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1121\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "#attempts at building the training loop\n",
    "\n",
    "for step, (x_batch, y_batch) in enumerate(train_ds_gen):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x_batch, y_batch = tf.convert_to_tensor(x_batch), tf.convert_to_tensor(y_batch)\n",
    "        logits = model(x_batch, training = True)\n",
    "        #logits = [np.random.randn() for emb in x_batch]\n",
    "        y_pos = [tf.math.argmax(label).numpy() for label in y_batch] #to find the actual node labels\n",
    "        loss_value = hdepp_loss(logits, y_pos, reference_tensor)\n",
    "        #loss_value = keras.losses.SparseCategoricalCrossentropy(from_logits = True)\n",
    "    \n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    print(step, loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d341cb4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#example of hdepp_loss working with labels a and embeddings b\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6]\n",
    "b = [[5, 8], [6, 7], [4, 8], [3, 7], [2, 8], [76, 6]]\n",
    "hdepp_loss(b, a, tree_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#poincare_dist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd52bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.GradientTape.gradient(7.4, model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tape.gradient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2a1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
